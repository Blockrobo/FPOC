---
annotation-target: 00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf
---


>%%
>```annotation-json
>{"created":"2023-11-18T15:06:02.476Z","text":"**Authors:**\n\n*  ́Angel Alexander Cabrer\n* Will Epperson \n* Fred Hohman \n* Minsuk Kahng\n* Jamie Morgenstern \n* Duen Horng (Polo) Chau","updated":"2023-11-18T15:06:02.476Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^x9zuzrr0o8|show annotation]]
>%%COMMENT%%
>**Authors:**
>
>*  ́Angel Alexander Cabrer
>* Will Epperson 
>* Fred Hohman 
>* Minsuk Kahng
>* Jamie Morgenstern 
>* Duen Horng (Polo) Chau
>%%TAGS%%
>#Angel_Alexander_Cabrera, #Will_Epperson, #Fred_Hohman, #Minusk_Kahng, #Jamie_Morgenstern, #Duen_Horng_Polo_Chau
^x9zuzrr0o8


>%%
>```annotation-json
>{"created":"2023-11-18T15:06:09.917Z","text":"**Topic:**\nAs a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems","updated":"2023-11-18T15:06:09.917Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^0smrun6p9o2|show annotation]]
>%%COMMENT%%
>**Topic:**
>As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems
>%%TAGS%%
>
^0smrun6p9o2


>%%
>```annotation-json
>{"created":"2023-11-18T15:06:17.824Z","text":"**Structure:**\n1. Introduction\n2. Background in machine Learning Fairness\n3. Related Work\n3.1 Intersectional Bias\n3.2 Visual Analytics for Machine Learning\n4. Design challenges and Goals\n4.1 Design Challenges\n4.2 Design Goals\n5. FAIRVIS: Discovering Intersectional Bias\n5.1 Feature Distribution View & Subgroup Creation\n....\n6. Use Cases","updated":"2023-11-18T15:06:17.824Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^o1xugh0yguf|show annotation]]
>%%COMMENT%%
>**Structure:**
>1. Introduction
>2. Background in machine Learning Fairness
>3. Related Work
>3.1 Intersectional Bias
>3.2 Visual Analytics for Machine Learning
>4. Design challenges and Goals
>4.1 Design Challenges
>4.2 Design Goals
>5. FAIRVIS: Discovering Intersectional Bias
>5.1 Feature Distribution View & Subgroup Creation
>....
>6. Use Cases
>%%TAGS%%
>
^o1xugh0yguf


>%%
>```annotation-json
>{"created":"2023-11-18T15:06:25.309Z","text":"**Keywords: **\nMachine learning fairness, visual analytics, intersec-\ntional bias, subgroup discovery","updated":"2023-11-18T15:06:25.309Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^mbgzpi121od|show annotation]]
>%%COMMENT%%
>**Keywords: **
>Machine learning fairness, visual analytics, intersec-
>tional bias, subgroup discovery
>%%TAGS%%
>#Machine_Learning, #Machine_Learning_Fairness, #Visual_Analytics, #Intersectional_Bias, #Subgroup_Discovery
^mbgzpi121od


>%%
>```annotation-json
>{"created":"2023-11-18T15:06:35.674Z","text":"**Publishing Year: **\n20-25 October 2019\n","updated":"2023-11-18T15:06:35.674Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^6790ftxekqc|show annotation]]
>%%COMMENT%%
>**Publishing Year: **
>20-25 October 2019
>
>%%TAGS%%
>#Publishing_Year_2019
^6790ftxekqc


>%%
>```annotation-json
>{"created":"2023-11-18T15:06:44.450Z","text":"**Literature Type: **\nPaper","updated":"2023-11-18T15:06:44.450Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^402zojdxid8|show annotation]]
>%%COMMENT%%
>**Literature Type: **
>Paper
>%%TAGS%%
>#Paper
^402zojdxid8


>%%
>```annotation-json
>{"created":"2023-11-18T15:06:56.726Z","text":"**Paper Type: **\nTechnique","updated":"2023-11-18T15:06:56.726Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^6asw36wh3q2|show annotation]]
>%%COMMENT%%
>**Paper Type: **
>Technique
>%%TAGS%%
>#Technique
^6asw36wh3q2


>%%
>```annotation-json
>{"created":"2023-11-18T15:07:03.831Z","text":"**Journal/Conference:**\n2019 IEEE Conference on Visual Analytics Science and Technology (VAST)\n","updated":"2023-11-18T15:07:03.831Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^1m1nopyau4g|show annotation]]
>%%COMMENT%%
>**Journal/Conference:**
>2019 IEEE Conference on Visual Analytics Science and Technology (VAST)
>
>%%TAGS%%
>#IEEE_Conference_on_Visual_Analytics_Science_and_Technology_VAST
^1m1nopyau4g


>%%
>```annotation-json
>{"created":"2023-11-18T15:07:13.497Z","text":"**Application Domain: **\nIn this section, we describe how FAIRVIS can be used in practice to audit models after they have been trained with two example usage scenarios. \n\nThe first scenario highlights how FAIRVIS can be used\nto audit models for biases against known vulnerable groups in thecontext of a recidivism prediction system. \n\nThe second use case\nshows how users without previous knowledge or intuitions about potential biases can use the system to find issues, for this example with an income prediction model. Both of these use cases utilize real world datasets to demonstrate the applications of our system","updated":"2023-11-18T15:07:13.497Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^sbihni2gvg|show annotation]]
>%%COMMENT%%
>**Application Domain: **
>In this section, we describe how FAIRVIS can be used in practice to audit models after they have been trained with two example usage scenarios. 
>
>The first scenario highlights how FAIRVIS can be used
>to audit models for biases against known vulnerable groups in thecontext of a recidivism prediction system. 
>
>The second use case
>shows how users without previous knowledge or intuitions about potential biases can use the system to find issues, for this example with an income prediction model. Both of these use cases utilize real world datasets to demonstrate the applications of our system
>%%TAGS%%
>#Model_Auditing, #Bias_Vulnerable_Groups, #Recidivism_Prediction_System
^sbihni2gvg


>%%
>```annotation-json
>{"created":"2023-11-18T15:09:36.830Z","updated":"2023-11-18T15:09:36.830Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":422,"end":483},{"type":"TextQuoteSelector","exact":"user investigates theintersectional subgroups of sex and race","prefix":"intersectional bias. Above, our ","suffix":". A. The Feature Distribution Vi"}]}]}
>```
>%%
>*%%PREFIX%%intersectional bias. Above, our%%HIGHLIGHT%% ==user investigates theintersectional subgroups of sex and race== %%POSTFIX%%. A. The Feature Distribution Vi*
>%%LINK%%[[#^v68rmcoxpd8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^v68rmcoxpd8


>%%
>```annotation-json
>{"created":"2023-11-18T15:09:57.385Z","updated":"2023-11-18T15:09:57.385Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":1527,"end":1585},{"type":"TextQuoteSelector","exact":"pplication to many real-world domains and data aboutpeople","prefix":"machine learning hasled to its a","suffix":". Despite the benefits algorithm"}]}]}
>```
>%%
>*%%PREFIX%%machine learning hasled to its a%%HIGHLIGHT%% ==pplication to many real-world domains and data aboutpeople== %%POSTFIX%%. Despite the benefits algorithm*
>%%LINK%%[[#^vu5ckrikq1i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vu5ckrikq1i


>%%
>```annotation-json
>{"created":"2023-11-18T15:10:08.783Z","updated":"2023-11-18T15:10:08.783Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":1738,"end":1781},{"type":"TextQuoteSelector","exact":"isadvantaging certain demographic subgroups","prefix":"etal biasesinto their outputs, d","suffix":".Discovering which biases a mach"}]}]}
>```
>%%
>*%%PREFIX%%etal biasesinto their outputs, d%%HIGHLIGHT%% ==isadvantaging certain demographic subgroups== %%POSTFIX%%.Discovering which biases a mach*
>%%LINK%%[[#^f1py32op1fk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f1py32op1fk


>%%
>```annotation-json
>{"created":"2023-11-18T15:10:24.308Z","updated":"2023-11-18T15:10:24.308Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":1988,"end":2140},{"type":"TextQuoteSelector","exact":"mixed-initiative visual analytics system that integrates anovel subgroup discovery technique for users to audit the fairnessof machine learning models. ","prefix":"subgroups. We presentFAIRVIS, a ","suffix":"Through FAIRVIS, users can apply"}]}]}
>```
>%%
>*%%PREFIX%%subgroups. We presentFAIRVIS, a%%HIGHLIGHT%% ==mixed-initiative visual analytics system that integrates anovel subgroup discovery technique for users to audit the fairnessof machine learning models.== %%POSTFIX%%Through FAIRVIS, users can apply*
>%%LINK%%[[#^7ndm2s5q6d8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7ndm2s5q6d8


>%%
>```annotation-json
>{"created":"2023-11-18T15:10:34.439Z","updated":"2023-11-18T15:10:34.439Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":2206,"end":2276},{"type":"TextQuoteSelector","exact":"nvestigate known subgroups, andexplore suggested and similar subgroups","prefix":"main knowledge to generate and i","suffix":". FAIRVIS’s coordinatedviews ena"}]}]}
>```
>%%
>*%%PREFIX%%main knowledge to generate and i%%HIGHLIGHT%% ==nvestigate known subgroups, andexplore suggested and similar subgroups== %%POSTFIX%%. FAIRVIS’s coordinatedviews ena*
>%%LINK%%[[#^tn5t0frvd3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tn5t0frvd3


>%%
>```annotation-json
>{"created":"2023-11-18T15:10:55.333Z","updated":"2023-11-18T15:10:55.333Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":2643,"end":2868},{"type":"TextQuoteSelector","exact":"visual analytics system devoted to discovering bias in machinelearning, FAIRVIS demonstrates how interactive visualization mayhelp data scientists and the general public understand and createmore equitable algorithmic systems","prefix":"ting income and recidivism.As a ","suffix":".Keywords: Machine learning fair"}]}]}
>```
>%%
>*%%PREFIX%%ting income and recidivism.As a%%HIGHLIGHT%% ==visual analytics system devoted to discovering bias in machinelearning, FAIRVIS demonstrates how interactive visualization mayhelp data scientists and the general public understand and createmore equitable algorithmic systems== %%POSTFIX%%.Keywords: Machine learning fair*
>%%LINK%%[[#^wm1mxruc8qn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wm1mxruc8qn


>%%
>```annotation-json
>{"created":"2023-11-18T15:28:51.979Z","text":"Application Domains\n","updated":"2023-11-18T15:28:51.979Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":3157,"end":3349},{"type":"TextQuoteSelector","exact":"new domainsin which these novel techniques are being applied are human-focusedand consequential, including hiring, predictive policing, predictingcriminal recidivism, and pedestrian detection.","prefix":" and complex tasks. Many of the ","suffix":" The latter two casesare example"}]}]}
>```
>%%
>*%%PREFIX%%and complex tasks. Many of the%%HIGHLIGHT%% ==new domainsin which these novel techniques are being applied are human-focusedand consequential, including hiring, predictive policing, predictingcriminal recidivism, and pedestrian detection.== %%POSTFIX%%The latter two casesare example*
>%%LINK%%[[#^ysh96drudi|show annotation]]
>%%COMMENT%%
>Application Domains
>
>%%TAGS%%
>
^ysh96drudi


>%%
>```annotation-json
>{"created":"2023-11-18T15:34:44.017Z","text":"Algorithmic Bias","updated":"2023-11-18T15:34:44.017Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":4221,"end":4367},{"type":"TextQuoteSelector","exact":"potential disparity in performance between populations mayhave many sources; an ML model can naturally encode implicit andexplicit societal biases","prefix":"rent subgroups of a dataset.The ","suffix":" [5], which is often referred to"}]}]}
>```
>%%
>*%%PREFIX%%rent subgroups of a dataset.The%%HIGHLIGHT%% ==potential disparity in performance between populations mayhave many sources; an ML model can naturally encode implicit andexplicit societal biases== %%POSTFIX%%[5], which is often referred to*
>%%LINK%%[[#^7iv6573bzt7|show annotation]]
>%%COMMENT%%
>Algorithmic Bias
>%%TAGS%%
>#Algorithmic_Bias
^7iv6573bzt7


>%%
>```annotation-json
>{"created":"2023-11-18T15:35:44.623Z","updated":"2023-11-18T15:35:44.623Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":4481,"end":4632},{"type":"TextQuoteSelector","exact":"training data may not be representative, either in terms of its rep-resentation of different demographic groups or within a particulardemographic group","prefix":"se for a variety of reasons: the","suffix":"; the training data labels may h"}]}]}
>```
>%%
>*%%PREFIX%%se for a variety of reasons: the%%HIGHLIGHT%% ==training data may not be representative, either in terms of its rep-resentation of different demographic groups or within a particulardemographic group== %%POSTFIX%%; the training data labels may h*
>%%LINK%%[[#^1ceo3okngdb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1ceo3okngdb


>%%
>```annotation-json
>{"created":"2023-11-18T15:36:20.393Z","updated":"2023-11-18T15:36:20.393Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":5286,"end":5425},{"type":"TextQuoteSelector","exact":" 90%, darker skinned women were classi-fied with accuracy as low as 65% while the models’ accuracies onlighter skinned men were nearly 100%","prefix":"models’accuracies hovered around","suffix":".In order to discover and addres"}]}]}
>```
>%%
>*%%PREFIX%%models’accuracies hovered around%%HIGHLIGHT%% ==90%, darker skinned women were classi-fied with accuracy as low as 65% while the models’ accuracies onlighter skinned men were nearly 100%== %%POSTFIX%%.In order to discover and addres*
>%%LINK%%[[#^hp0jv4ltk5c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hp0jv4ltk5c


>%%
>```annotation-json
>{"created":"2023-11-18T15:36:49.761Z","updated":"2023-11-18T15:36:49.761Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":5707,"end":5895},{"type":"TextQuoteSelector","exact":"Intersectional bias is bias that is present when looking atpopulations that are defined by multiple features, for example “BlackFemales” instead of just people who are “Black” or “Female”.","prefix":"own by Buolamwini andGebru [7]. ","suffix":" Thedifficulty in finding inters"}]}]}
>```
>%%
>*%%PREFIX%%own by Buolamwini andGebru [7].%%HIGHLIGHT%% ==Intersectional bias is bias that is present when looking atpopulations that are defined by multiple features, for example “BlackFemales” instead of just people who are “Black” or “Female”.== %%POSTFIX%%Thedifficulty in finding inters*
>%%LINK%%[[#^km5l7jr9ve|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^km5l7jr9ve


>%%
>```annotation-json
>{"created":"2023-11-18T15:37:30.002Z","updated":"2023-11-18T15:37:30.002Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":7197,"end":7316},{"type":"TextQuoteSelector","exact":"Data scientists often have to balance the tradeoffs between variousfairness metrics when making changes to their models","prefix":"nd quickly becomes unmanageable.","suffix":".To help data scientists better "}]}]}
>```
>%%
>*%%PREFIX%%nd quickly becomes unmanageable.%%HIGHLIGHT%% ==Data scientists often have to balance the tradeoffs between variousfairness metrics when making changes to their models== %%POSTFIX%%.To help data scientists better*
>%%LINK%%[[#^y3loue4wzur|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^y3loue4wzur


>%%
>```annotation-json
>{"created":"2023-11-18T15:37:46.522Z","updated":"2023-11-18T15:37:46.522Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":7612,"end":7760},{"type":"TextQuoteSelector","exact":"mixed-initiative system that allows users to exploreboth suggested and user-specified subgroups that incorporate auser’s existing domain knowledge. ","prefix":"ntersectional bias.FAIRVIS is a ","suffix":"Users can visualize how thesegro"}]}]}
>```
>%%
>*%%PREFIX%%ntersectional bias.FAIRVIS is a%%HIGHLIGHT%% ==mixed-initiative system that allows users to exploreboth suggested and user-specified subgroups that incorporate auser’s existing domain knowledge.== %%POSTFIX%%Users can visualize how thesegro*
>%%LINK%%[[#^ecspf80fsjd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ecspf80fsjd


>%%
>```annotation-json
>{"created":"2023-11-18T15:38:21.424Z","updated":"2023-11-18T15:38:21.424Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":8789,"end":8890},{"type":"TextQuoteSelector","exact":"We first run clustering on the training dataset to find statisti-cally similar subgroups of instances","prefix":" a model may be underperforming.","suffix":". Next, we use an entropytechniq"}]}]}
>```
>%%
>*%%PREFIX%%a model may be underperforming.%%HIGHLIGHT%% ==We first run clustering on the training dataset to find statisti-cally similar subgroups of instances== %%POSTFIX%%. Next, we use an entropytechniq*
>%%LINK%%[[#^eim8pr74lh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^eim8pr74lh


>%%
>```annotation-json
>{"created":"2023-11-18T15:39:25.048Z","updated":"2023-11-18T15:39:25.048Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":10037,"end":10220},{"type":"TextQuoteSelector","exact":"ajor difficulty in machine learning fairness is that it is mathe-matically impossible to fulfill all definitions of fairness simultane-ously when populations have different base rates","prefix":" impacts of machine learning.A m","suffix":". This incompati-bility between "}]}]}
>```
>%%
>*%%PREFIX%%impacts of machine learning.A m%%HIGHLIGHT%% ==ajor difficulty in machine learning fairness is that it is mathe-matically impossible to fulfill all definitions of fairness simultane-ously when populations have different base rates== %%POSTFIX%%. This incompati-bility between*
>%%LINK%%[[#^udbdhyi8bm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^udbdhyi8bm


>%%
>```annotation-json
>{"created":"2023-11-18T15:39:39.360Z","text":"A major difficulty in machine learning fairness is that it is mathematically impossible to fulfill all definitions of fairness simultane ously when populations have different base rates","updated":"2023-11-18T15:39:39.360Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":10290,"end":10337},{"type":"TextQuoteSelector","exact":" impossibilitytheorem for fair machine learning","prefix":"ss metrics was formalized by the","suffix":". Two papers [14, 24] simultane-"}]}]}
>```
>%%
>*%%PREFIX%%ss metrics was formalized by the%%HIGHLIGHT%% ==impossibilitytheorem for fair machine learning== %%POSTFIX%%. Two papers [14, 24] simultane-*
>%%LINK%%[[#^7ig8mp2kyyq|show annotation]]
>%%COMMENT%%
>A major difficulty in machine learning fairness is that it is mathematically impossible to fulfill all definitions of fairness simultane ously when populations have different base rates
>%%TAGS%%
>#Impossibility_Theorem
^7ig8mp2kyyq


>%%
>```annotation-json
>{"created":"2023-11-18T15:40:55.335Z","updated":"2023-11-18T15:40:55.335Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":10618,"end":10694},{"type":"TextQuoteSelector","exact":"Data scientists must thereforedecide which fairness metrics to prioritize in","prefix":", and calibration of the model. ","suffix":" a model and how tomake trade-of"}]}]}
>```
>%%
>*%%PREFIX%%, and calibration of the model.%%HIGHLIGHT%% ==Data scientists must thereforedecide which fairness metrics to prioritize in== %%POSTFIX%%a model and how tomake trade-of*
>%%LINK%%[[#^hbyzxpb9g1r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hbyzxpb9g1r


>%%
>```annotation-json
>{"created":"2023-11-18T15:41:08.174Z","updated":"2023-11-18T15:41:08.174Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":10959,"end":11044},{"type":"TextQuoteSelector","exact":"COMPAS is more likely to rank a Black defendant ashigher risk than a White defendant ","prefix":"oPublica article [3]showed that ","suffix":"given that they have equal baser"}]}]}
>```
>%%
>*%%PREFIX%%oPublica article [3]showed that%%HIGHLIGHT%% ==COMPAS is more likely to rank a Black defendant ashigher risk than a White defendant== %%POSTFIX%%given that they have equal baser*
>%%LINK%%[[#^kzbqb63grzj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kzbqb63grzj


>%%
>```annotation-json
>{"created":"2023-11-18T15:41:39.870Z","updated":"2023-11-18T15:41:39.870Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":11983,"end":12181},{"type":"TextQuoteSelector","exact":"While these can help balance certain inequities, theimpossibility theorem dictates that hard decisions will still have to bemade about which fairness metrics are the most important for eachproblem. ","prefix":"ing noise to pre-dictions [17]. ","suffix":"Ideally, over time these will be"}]}]}
>```
>%%
>*%%PREFIX%%ing noise to pre-dictions [17].%%HIGHLIGHT%% ==While these can help balance certain inequities, theimpossibility theorem dictates that hard decisions will still have to bemade about which fairness metrics are the most important for eachproblem.== %%POSTFIX%%Ideally, over time these will be*
>%%LINK%%[[#^9f3b70x5s7h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9f3b70x5s7h


>%%
>```annotation-json
>{"created":"2023-11-18T15:43:56.735Z","updated":"2023-11-18T15:43:56.735Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":13151,"end":13239},{"type":"TextQuoteSelector","exact":"im to operate in a spacewhere a predefined notion of groups is not necessarily available","prefix":"in several key ways. First, we a","suffix":",and so cooperation between an a"}]}]}
>```
>%%
>*%%PREFIX%%in several key ways. First, we a%%HIGHLIGHT%% ==im to operate in a spacewhere a predefined notion of groups is not necessarily available== %%POSTFIX%%,and so cooperation between an a*
>%%LINK%%[[#^dpbuutrfn3l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dpbuutrfn3l


>%%
>```annotation-json
>{"created":"2023-11-18T15:44:14.188Z","updated":"2023-11-18T15:44:14.188Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":14060,"end":14293},{"type":"TextQuoteSelector","exact":" SliceFinder [9], a technique for automatically generating subgroups. SliceFinder takes a top-down approach to generating subgroups, addingfeatures to create more granular groups until the training loss is statis-tically significant.","prefix":"ias. Most similar to our work is","suffix":" Our technique for automated sub"}]}]}
>```
>%%
>*%%PREFIX%%ias. Most similar to our work is%%HIGHLIGHT%% ==SliceFinder [9], a technique for automatically generating subgroups. SliceFinder takes a top-down approach to generating subgroups, addingfeatures to create more granular groups until the training loss is statis-tically significant.== %%POSTFIX%%Our technique for automated sub*
>%%LINK%%[[#^cbl4akvs0nd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cbl4akvs0nd


>%%
>```annotation-json
>{"created":"2023-11-18T15:44:26.665Z","text":"Techniwur used for Sub-Group Discovery\n","updated":"2023-11-18T15:44:26.665Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":14295,"end":14425},{"type":"TextQuoteSelector","exact":"ur technique for automated subgroup discoveryis bottom-up, clustering instances without imposing any structure onthe features used","prefix":"is statis-tically significant. O","suffix":". In addition to potentially gen"}]}]}
>```
>%%
>*%%PREFIX%%is statis-tically significant. O%%HIGHLIGHT%% ==ur technique for automated subgroup discoveryis bottom-up, clustering instances without imposing any structure onthe features used== %%POSTFIX%%. In addition to potentially gen*
>%%LINK%%[[#^4r00dgswmrm|show annotation]]
>%%COMMENT%%
>Techniwur used for Sub-Group Discovery
>
>%%TAGS%%
>
^4r00dgswmrm


>%%
>```annotation-json
>{"created":"2023-11-18T15:44:55.126Z","updated":"2023-11-18T15:44:55.126Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":14783,"end":14911},{"type":"TextQuoteSelector","exact":"Various systems have been created focused on helping usersunderstand how complex models work and visually debugging theiroutputs","prefix":"ning models [2, 22, 25,30, 32]. ","suffix":" [33]. Additionally, systems hav"}]}]}
>```
>%%
>*%%PREFIX%%ning models [2, 22, 25,30, 32].%%HIGHLIGHT%% ==Various systems have been created focused on helping usersunderstand how complex models work and visually debugging theiroutputs== %%POSTFIX%%[33]. Additionally, systems hav*
>%%LINK%%[[#^uabkyofcnd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uabkyofcnd


>%%
>```annotation-json
>{"created":"2023-11-18T15:46:11.823Z","updated":"2023-11-18T15:46:11.823Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":16586,"end":16772},{"type":"TextQuoteSelector","exact":"While the What-If tool is a powerful data explo-ration tool, it does not allow users to explore intersectional bias nordoes it aid users in auditing the performance of specific subgroups","prefix":" principlesare being satisfied. ","suffix":".4 DESIGN CHALLENGES AND GOALSOu"}]}]}
>```
>%%
>*%%PREFIX%%principlesare being satisfied.%%HIGHLIGHT%% ==While the What-If tool is a powerful data explo-ration tool, it does not allow users to explore intersectional bias nordoes it aid users in auditing the performance of specific subgroups== %%POSTFIX%%.4 DESIGN CHALLENGES AND GOALSOu*
>%%LINK%%[[#^l721wrmy0zi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^l721wrmy0zi


>%%
>```annotation-json
>{"created":"2023-11-18T15:46:21.192Z","updated":"2023-11-18T15:46:21.192Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":16174,"end":16323},{"type":"TextQuoteSelector","exact":" What-If tool is a more general data explorationtool that combines dataset exploration with counterfactual explana-tions and fairness modifications. ","prefix":"hat-If tool fromGoogle [16]. The","suffix":"Users can explore a dataset usin"}]}]}
>```
>%%
>*%%PREFIX%%hat-If tool fromGoogle [16]. The%%HIGHLIGHT%% ==What-If tool is a more general data explorationtool that combines dataset exploration with counterfactual explana-tions and fairness modifications.== %%POSTFIX%%Users can explore a dataset usin*
>%%LINK%%[[#^2x86a2sm85t|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2x86a2sm85t


>%%
>```annotation-json
>{"created":"2023-11-18T15:46:28.684Z","updated":"2023-11-18T15:46:28.684Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":16826,"end":16950},{"type":"TextQuoteSelector","exact":"interactive visual interface to help usersexplore the fairness of their machine learning models and discoverpotential biases","prefix":"ND GOALSOur goal is to build an ","suffix":". Many of the challenges present"}]}]}
>```
>%%
>*%%PREFIX%%ND GOALSOur goal is to build an%%HIGHLIGHT%% ==interactive visual interface to help usersexplore the fairness of their machine learning models and discoverpotential biases== %%POSTFIX%%. Many of the challenges present*
>%%LINK%%[[#^bpruvrakm9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bpruvrakm9


>%%
>```annotation-json
>{"created":"2023-11-18T15:48:09.101Z","updated":"2023-11-18T15:48:09.101Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":20018,"end":20172},{"type":"TextQuoteSelector","exact":"How toaddress bias in machine learning models is a difficult and open ques-tion, but there are indicators that can help users start to improve theirmodels","prefix":"tial causes of biased behavior. ","suffix":". Emphasizing information like g"}]}]}
>```
>%%
>*%%PREFIX%%tial causes of biased behavior.%%HIGHLIGHT%% ==How toaddress bias in machine learning models is a difficult and open ques-tion, but there are indicators that can help users start to improve theirmodels== %%POSTFIX%%. Emphasizing information like g*
>%%LINK%%[[#^g701fhu5n1m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^g701fhu5n1m


>%%
>```annotation-json
>{"created":"2023-11-18T15:48:54.443Z","text":"https://poloclub.github.io/FairVis/\n","updated":"2023-11-18T15:48:54.443Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":22990,"end":23231},{"type":"TextQuoteSelector","exact":"veloped FAIRVIS, a visual analytics system for discovering inter-sectional bias in machine learning models. To meet the listed designgoals, we developed two novel techniques to generate underper-forming subgroups and find similar subgroups. ","prefix":"troduced in Section 4, we havede","suffix":"We combine thesetechniques in a "}]}]}
>```
>%%
>*%%PREFIX%%troduced in Section 4, we havede%%HIGHLIGHT%% ==veloped FAIRVIS, a visual analytics system for discovering inter-sectional bias in machine learning models. To meet the listed designgoals, we developed two novel techniques to generate underper-forming subgroups and find similar subgroups.== %%POSTFIX%%We combine thesetechniques in a*
>%%LINK%%[[#^3x08rd6sp0t|show annotation]]
>%%COMMENT%%
>https://poloclub.github.io/FairVis/
>
>%%TAGS%%
>
^3x08rd6sp0t


>%%
>```annotation-json
>{"created":"2023-11-18T15:54:24.854Z","updated":"2023-11-18T15:54:24.854Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":48093,"end":48159},{"type":"TextQuoteSelector","exact":"can be used in practiceto audit models after they have been traine","prefix":"ection, we describe how FAIRVIS ","suffix":"d with two example usagescenario"}]}]}
>```
>%%
>*%%PREFIX%%ection, we describe how FAIRVIS%%HIGHLIGHT%% ==can be used in practiceto audit models after they have been traine== %%POSTFIX%%d with two example usagescenario*
>%%LINK%%[[#^6aaxt9sdjmy|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6aaxt9sdjmy


>%%
>```annotation-json
>{"created":"2023-11-18T15:54:31.617Z","updated":"2023-11-18T15:54:31.617Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":48228,"end":48305},{"type":"TextQuoteSelector","exact":"FAIRVIS can be usedto audit models for biases against known vulnerable groups","prefix":"e first scenario highlights how ","suffix":" in thecontext of a recidivism p"}]}]}
>```
>%%
>*%%PREFIX%%e first scenario highlights how%%HIGHLIGHT%% ==FAIRVIS can be usedto audit models for biases against known vulnerable groups== %%POSTFIX%%in thecontext of a recidivism p*
>%%LINK%%[[#^roqcssot9d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^roqcssot9d


>%%
>```annotation-json
>{"created":"2023-11-18T15:54:41.906Z","updated":"2023-11-18T15:54:41.906Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":48384,"end":48536},{"type":"TextQuoteSelector","exact":"users without previous knowledge or intuitions aboutpotential biases can use the system to find issues, for this examplewith an income prediction model.","prefix":"m. The second use caseshows how ","suffix":" Both of these use cases utilize"}]}]}
>```
>%%
>*%%PREFIX%%m. The second use caseshows how%%HIGHLIGHT%% ==users without previous knowledge or intuitions aboutpotential biases can use the system to find issues, for this examplewith an income prediction model.== %%POSTFIX%%Both of these use cases utilize*
>%%LINK%%[[#^m11c3gqcnab|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^m11c3gqcnab


>%%
>```annotation-json
>{"created":"2023-11-18T15:55:03.037Z","updated":"2023-11-18T15:55:03.037Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","target":[{"source":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","selector":[{"type":"TextPositionSelector","start":60189,"end":60274},{"type":"TextQuoteSelector","exact":"FAIRVIS is a web-based system built using the open-sourcedJavaScript framework React.","prefix":"ncies.7 TECHNICAL IMPLEMENTATION","suffix":" Many additional libraries were "}]}]}
>```
>%%
>*%%PREFIX%%ncies.7 TECHNICAL IMPLEMENTATION%%HIGHLIGHT%% ==FAIRVIS is a web-based system built using the open-sourcedJavaScript framework React.== %%POSTFIX%%Many additional libraries were*
>%%LINK%%[[#^ssxz8v9xn8d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ssxz8v9xn8d
^ptbc4epsmgc
>%%
>```annotation-json
>{"created":"2024-01-08T10:57:39.090Z","text":"**Storytelling:**","updated":"2024-01-08T10:57:39.090Z","document":{"title":"A Layered Grammar of Graphics","link":[{"href":"urn:x-pdf:ea4f3b35ca98be41a2887c706124615f"},{"href":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}],"documentFingerprint":"ea4f3b35ca98be41a2887c706124615f"},"uri":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^hv4iz2v0dgl|show annotation]]
>%%COMMENT%%
>**Storytelling:**
>%%TAGS%%
>
^hv4iz2v0dgl


>%%
>```annotation-json
>{"text":"**Contextual Sensitivity:**","created":"2024-01-08T10:58:00.343Z","updated":"2024-01-08T10:58:00.343Z","document":{"title":"A Layered Grammar of Graphics","link":[{"href":"urn:x-pdf:ea4f3b35ca98be41a2887c706124615f"},{"href":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}],"documentFingerprint":"ea4f3b35ca98be41a2887c706124615f"},"uri":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^qv68q5116n7|show annotation]]
>%%COMMENT%%
>**Contextual Sensitivity:**
>%%TAGS%%
>#CS_emphasized
^qv68q5116n7


>%%
>```annotation-json
>{"text":"**Emotion & Empathy**","created":"2024-01-08T10:58:29.023Z","updated":"2024-01-08T10:58:29.023Z","document":{"title":"A Layered Grammar of Graphics","link":[{"href":"urn:x-pdf:ea4f3b35ca98be41a2887c706124615f"},{"href":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}],"documentFingerprint":"ea4f3b35ca98be41a2887c706124615f"},"uri":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^gclnex805i|show annotation]]
>%%COMMENT%%
>**Emotion & Empathy**
>%%TAGS%%
>#CS_ignored
^gclnex805i


>%%
>```annotation-json
>{"text":"**Algorithmic Self: **","created":"2024-01-08T10:58:40.973Z","updated":"2024-01-08T10:58:40.973Z","document":{"title":"A Layered Grammar of Graphics","link":[{"href":"urn:x-pdf:ea4f3b35ca98be41a2887c706124615f"},{"href":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}],"documentFingerprint":"ea4f3b35ca98be41a2887c706124615f"},"uri":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^icvhlx0kul|show annotation]]
>%%COMMENT%%
>**Algorithmic Self: **
>%%TAGS%%
>#AS_superficially_recognized
^icvhlx0kul


>%%
>```annotation-json
>{"text":"**Cognitive Load: **","created":"2024-01-08T10:58:57.413Z","updated":"2024-01-08T10:58:57.413Z","document":{"title":"A Layered Grammar of Graphics","link":[{"href":"urn:x-pdf:ea4f3b35ca98be41a2887c706124615f"},{"href":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}],"documentFingerprint":"ea4f3b35ca98be41a2887c706124615f"},"uri":"vault:/PDFs/00001 A Layered Grammar of Graphics.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^7n8si5uco9x|show annotation]]
>%%COMMENT%%
>**Cognitive Load: **
>%%TAGS%%
>#CL_high_load
^7n8si5uco9x


>%%
>```annotation-json
>{"text":"ST","created":"2024-01-08T12:29:09.783Z","updated":"2024-01-08T12:29:09.783Z","document":{"title":"00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf","link":[{"href":"urn:x-pdf:53745c307d1d2043b99800517360928f"},{"href":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}],"documentFingerprint":"53745c307d1d2043b99800517360928f"},"uri":"vault:/PDFs/00007 FAIRVIS_Visual_Analytics_for_Discovering_Intersectional_Bias_in_Machine_Learning.pdf"}
>```
>%%
>*%%PREFIX%%%%HIGHLIGHT%% ==== %%POSTFIX%%*
>%%LINK%%[[#^24459xzgogc|show annotation]]
>%%COMMENT%%
>ST
>%%TAGS%%
>#ST_absent
^24459xzgogc
